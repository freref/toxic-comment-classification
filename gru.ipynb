{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44b3a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Bidirectional, GRU, GlobalMaxPool1D, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "410b7068",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "list_sentences = train[\"comment_text\"].fillna(\"_na_\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5aac483",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 200\n",
    "embed_size = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences)\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca90310",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open('data/glove.6B.100d.txt', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca1c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(GRU(128, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_t, \n",
    "    y, \n",
    "    batch_size=32, \n",
    "    epochs=2, \n",
    "    validation_split=0.1, \n",
    ")\n",
    "\n",
    "model.save(\"models/toxic_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "650d5a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fre/Documents/University/2025-2026/FCL/project/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 13 variables whereas the saved optimizer has 24 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"models/toxic_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f503efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 47ms/step\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "list_sentences_test = test[\"comment_text\"].fillna(\"_na_\").values\n",
    "y_test_true = test[list_classes].values\n",
    "\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_test = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
    "\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cdaf85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9801604154054294\n",
      "        Class  AUC_ROC_Score\n",
      "       threat       0.990243\n",
      " severe_toxic       0.989750\n",
      "identity_hate       0.981485\n",
      "      obscene       0.977440\n",
      "       insult       0.975145\n",
      "        toxic       0.966900\n"
     ]
    }
   ],
   "source": [
    "mean_auc = roc_auc_score(y_test_true, y_test_pred, average='macro')\n",
    "\n",
    "print(mean_auc)\n",
    "\n",
    "per_class_auc_scores = roc_auc_score(y_test_true, y_test_pred, average=None)\n",
    "\n",
    "auc_report = pd.DataFrame({\n",
    "    'Class': list_classes,\n",
    "    'AUC_ROC_Score': per_class_auc_scores\n",
    "})\n",
    "\n",
    "auc_report_sorted = auc_report.sort_values(by='AUC_ROC_Score', ascending=False)\n",
    "print(auc_report_sorted.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46312459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1: 0.5665\n",
      "Micro F1: 0.6659\n",
      "        Class  F1_Score\n",
      "      obscene  0.688336\n",
      "        toxic  0.678609\n",
      "       insult  0.668414\n",
      "identity_hate  0.582278\n",
      "       threat  0.399015\n",
      " severe_toxic  0.382482\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_binary_simple = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "macro_f1_simple = f1_score(y_test_true, y_test_pred_binary_simple, average='macro')\n",
    "micro_f1_simple = f1_score(y_test_true, y_test_pred_binary_simple, average='micro')\n",
    "\n",
    "print(f\"Macro F1: {macro_f1_simple:.4f}\")\n",
    "print(f\"Micro F1: {micro_f1_simple:.4f}\")\n",
    "\n",
    "simple_f1_scores = f1_score(y_test_true, y_test_pred_binary_simple, average=None)\n",
    "\n",
    "f1_report_simple = pd.DataFrame({\n",
    "    'Class': list_classes,\n",
    "    'F1_Score': simple_f1_scores\n",
    "})\n",
    "\n",
    "print(f1_report_simple.sort_values(by='F1_Score', ascending=False).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
