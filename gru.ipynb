{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81f2299e",
   "metadata": {},
   "source": [
    "# Deep Learning Paradigm: Bidirectional GRU\n",
    "I selected a **Bidirectional GRU** as the neural network paradigm for this problem. While Naive Bayes relies on simple word counts, this Recurrent Neural Network (RNN) processes text as a sequence, allowing it to capture context and word order. This offers a distinct trade-off compared to the statistical approach:\n",
    "\n",
    "- **Efficiency:** It is computationally expensive. While Naive Bayes trained instantly, this model required significantly more time (approx. 40 minutes) to converge over just 2 epochs.\n",
    "- **Performance:** The computational cost has a massive gain in predictive power. As detailed below, the Bi-GRU outperforms Naive Bayes across all metrics, particularly in distinguishing difficult, rare classes.\n",
    "- **Context Awareness:** Unlike the \"TF-IDF\" model which treats \"not good\" and \"good\" similarly (just checking for the presence of words), the Bi-GRU understands that \"not\" negates \"good\" because it sees the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a44b3a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Bidirectional, GRU, GlobalMaxPool1D, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "410b7068",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "list_sentences = train[\"comment_text\"].fillna(\"_na_\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0752dc",
   "metadata": {},
   "source": [
    "In the statistical approach, I used TF-IDF to weigh words by rarity. Here, I use Word Embeddings. I map each word to a pre-trained vector (GloVe) of 100 dimensions. This allows the model to understand semantic relationships—it knows that \"stupid\" and \"idiot\" are mathematically similar vectors, whereas TF-IDF treats them as completely unrelated tokens (orthogonal). I limit the vocabulary to the top 20,000 words and pad all comments to a fixed length of 200 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5aac483",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 200\n",
    "embed_size = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences)\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dca90310",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open('data/glove.6B.100d.txt', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033ebd37",
   "metadata": {},
   "source": [
    "I define a Keras model that starts with an Embedding layer initialized with the GloVe weights. This feeds into a Bidirectional GRU layer, which reads the comment both forwards and backwards to capture maximum context. I use GlobalMaxPool1D to reduce the dimensionality and extract the most salient features (the strongest signals of toxicity) before passing them to a Dense layer and a final Sigmoid output layer for multi-label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aca1c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(GRU(128, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4986cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_t, \n",
    "    y, \n",
    "    batch_size=32, \n",
    "    epochs=2, \n",
    "    validation_split=0.1, \n",
    ")\n",
    "\n",
    "model.save(\"models/toxic_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d5a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fre/Documents/University/2025-2026/FCL/project/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 13 variables whereas the saved optimizer has 24 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"models/toxic_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f503efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 60ms/step\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "list_sentences_test = test[\"comment_text\"].fillna(\"_na_\").values\n",
    "y_test_true = test[list_classes].values\n",
    "\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_test = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
    "\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a95f49d",
   "metadata": {},
   "source": [
    "I achieved a Macro AUC of 0.9802, which is a significant improvement over the Naive Bayes score of 0.9315. The most impressive gain is in the Threat class, which jumped from 0.90 (in Naive Bayes) to 0.99 here. This shows that the neural network is much better at detecting rare, context-dependent classes that the statistical model struggled with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdaf85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9801604154054294\n",
      "        Class  AUC_ROC_Score\n",
      "       threat       0.990243\n",
      " severe_toxic       0.989750\n",
      "identity_hate       0.981485\n",
      "      obscene       0.977440\n",
      "       insult       0.975145\n",
      "        toxic       0.966900\n"
     ]
    }
   ],
   "source": [
    "mean_auc = roc_auc_score(y_test_true, y_test_pred, average='macro')\n",
    "\n",
    "print(mean_auc)\n",
    "\n",
    "per_class_auc_scores = roc_auc_score(y_test_true, y_test_pred, average=None)\n",
    "\n",
    "auc_report = pd.DataFrame({\n",
    "    'Class': list_classes,\n",
    "    'AUC_ROC_Score': per_class_auc_scores\n",
    "})\n",
    "\n",
    "auc_report_sorted = auc_report.sort_values(by='AUC_ROC_Score', ascending=False)\n",
    "print(auc_report_sorted.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b9060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step\n"
     ]
    }
   ],
   "source": [
    "val_size = int(len(X_t) * 0.1)\n",
    "X_val = X_t[-val_size:]\n",
    "y_val = y[-val_size:]\n",
    "\n",
    "y_val_proba = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46312459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Threshold found: 0.45\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_val_pred_binary = (y_val_proba > thresh).astype(int)\n",
    "    \n",
    "    current_f1 = f1_score(y_val, y_val_pred_binary, average='micro')\n",
    "    \n",
    "    if current_f1 > best_f1:\n",
    "        best_f1 = current_f1\n",
    "        best_threshold = thresh\n",
    "\n",
    "print(f\"\\nBest Threshold found: {best_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184ba875",
   "metadata": {},
   "source": [
    "By optimizing the decision boundary on the validation set, I found the best threshold to be 0.45, which gives a Macro F1 of 0.5764.\n",
    "\n",
    "This result confirms the that the Deep Learning approach has a higher accuracy than the statistical baseline (0.36 Macro F1). While the Naive Bayes model required a drastic threshold drop to 0.25 to detect minority classes, the Bi-GRU is naturally well-calibrated near the default. The biggest improvement is in the rare classes: 'threat' jumped from a non-existent 0.00 to 0.42, and 'identity_hate' went from 0.13 to 0.59, showing that the semantic embeddings successfully captured context that TF-IDF didn't have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "091832a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1: 0.5764\n",
      "Micro F1: 0.6563\n",
      "        Class  F1_Score\n",
      "      obscene  0.676128\n",
      "       insult  0.666005\n",
      "        toxic  0.664232\n",
      "identity_hate  0.595273\n",
      " severe_toxic  0.432251\n",
      "       threat  0.424658\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_binary_simple = (y_test_pred > best_threshold).astype(int)\n",
    "\n",
    "macro_f1_simple = f1_score(y_test_true, y_test_pred_binary_simple, average='macro')\n",
    "micro_f1_simple = f1_score(y_test_true, y_test_pred_binary_simple, average='micro')\n",
    "\n",
    "print(f\"Macro F1: {macro_f1_simple:.4f}\")\n",
    "print(f\"Micro F1: {micro_f1_simple:.4f}\")\n",
    "\n",
    "simple_f1_scores = f1_score(y_test_true, y_test_pred_binary_simple, average=None)\n",
    "\n",
    "f1_report_simple = pd.DataFrame({\n",
    "    'Class': list_classes,\n",
    "    'F1_Score': simple_f1_scores\n",
    "})\n",
    "\n",
    "print(f1_report_simple.sort_values(by='F1_Score', ascending=False).to_string(index=False))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
